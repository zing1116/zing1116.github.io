<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ZING&#39;S BLOG</title>
  
  <subtitle>zzingsub</subtitle>
  <link href="https://zing1116.works/atom.xml" rel="self"/>
  
  <link href="https://zing1116.works/"/>
  <updated>2020-11-20T15:58:18.323Z</updated>
  <id>https://zing1116.works/</id>
  
  <author>
    <name>Zing_zyy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python爬取贴吧图片（含urllib库和requests库的两种爬取方式）</title>
    <link href="https://zing1116.works/2020/03/22/tieba/"/>
    <id>https://zing1116.works/2020/03/22/tieba/</id>
    <published>2020-03-22T12:40:05.000Z</published>
    <updated>2020-11-20T15:58:18.323Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;重新温习一下被放下太久的Python爬虫技能，这次试着爬一下ID:INVADED 异度侵入贴吧的图片。<del><em>（今晚还要等着最后一集更新呢…</em></del></p><h3 id="环境及涉及库"><a href="#环境及涉及库" class="headerlink" title="环境及涉及库"></a>环境及涉及库</h3><p> · Python3.6<br> · urllib<br> · requests<br> · re</p><h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><p> · 爬取过程<br> · <code>urllib</code>库和<code>requests</code>库的区分<br><br></p><h2 id="页面获取"><a href="#页面获取" class="headerlink" title="页面获取"></a>页面获取</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先随便进入一个 <a href="https://tieba.baidu.com/p/6520552534">帖子</a>，都是官推图，就选你了。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;帖子一进去界面长这样。<br><img src="https://img-blog.csdnimg.cn/20200322163818356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后键盘按下F12，打开浏览器控制台，再刷新界面。在<strong>Network</strong>分类下，观察到控制台显示了页面中各项的请求和回应报文详情。随便点击一个项，可以在其右侧的<strong>Headers</strong>中找到<strong>Request Headers</strong>的信息。<br><img src="https://img-blog.csdnimg.cn/20200322164305881.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;==先说明一下为什么要找这个<strong>Headers</strong>信息==，为了维护各公司网站的资源，现在各网站大都配有反爬虫机制，就是为了防止网站资源被随意批量的窃取。如果你的ip连续多次访问某一含反爬虫机制的网站，你的ip就会被网站检测到，并限制你的ip访问或是将你的ip访问禁止。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以这就需要我们每次访问都变更自己的ip或是将我们的访问伪装成浏览器访问。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;变更ip可以使用高匿的ip代理，这里推荐一个网站 <a href="https://www.xicidaili.com/">西刺代理</a>，里面有各种国内免费高匿ip供你选择，就是质量不太好，<del><em>因为是免费…</em></del> &nbsp;&nbsp;经常要更换，并且还要看脸…所以在这里不推荐使用第一种方法。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在的反爬虫绕过的普遍方法还是伪装成浏览器访问，而伪装成浏览器就只需伪装浏览器的请求报文中的<strong>Headers</strong>即可。所以 ==用浏览器查看请求报文的内容就是为了反爬虫绕过啦。== </p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>回到正题</strong> ，伪装Headers其实最重要的就是伪装<strong>User-Agent</strong>这一项，或者再加上<strong>Host</strong>字段。<br><img src="https://img-blog.csdnimg.cn/20200322171218193.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Py文件中创建一个<code>Headers</code>字典，分别将这两项的名称和内容作为键和键值。这样我们的请求头就构建好啦。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64)\</span></span><br><span class="line"><span class="string">     AppleWebKit/537.36 (KHTML, like Gecko)\</span></span><br><span class="line"><span class="string">     Chrome/65.0.3314.0 Safari/537.36 SE 2.X MetaSr 1.0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;tieba.baidu.com&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;开始获取页面信息，先<code>import requests</code>，使用<code>get</code>方法进行获取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span>(<span class="params">url,headers</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url,headers)</span><br><span class="line">        r.encoding=<span class="string">&#x27;utf8&#x27;</span> <span class="comment"># 将对象编码转换成UTF-8编码</span></span><br><span class="line">        html=r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">&quot;failed to geturl&quot;</span>) <span class="comment"># 如果网络连接异常，则报错。</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> html</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;来先尝试一下能不能成功获取到html文本，输入以下代码测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=getHtml(url,headers).text</span><br><span class="line">print(t)</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果如下：<br><img src="https://img-blog.csdnimg.cn/20200322173228582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;嗯，获取成功！</p><br><h2 id="目标提取"><a href="#目标提取" class="headerlink" title="目标提取"></a>目标提取</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要在这些获取到的html文本中找到帖子中的图片链接，需要用到正则表达式的方法（当然也可以用BeautifulSoup匹配）。首先<code>import re</code>，回到浏览器控制台，在<strong>Element</strong>分类下寻找存储图片链接的地方，一般都在<strong>body</strong>类下面。<br><img src="https://img-blog.csdnimg.cn/20200322174517638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对应的文本部分为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;img class&#x3D;&quot;BDE_Image&quot; src&#x3D;&quot;http:&#x2F;&#x2F;tiebapic.baidu.com&#x2F;forum&#x2F;w%3D580&#x2F;sign&#x3D;b352f09cc239b6004dce0fbfd9513526&#x2F;27284b638535e5dd418d56a061c6a7efcf1b621c.jpg&quot; size&#x3D;&quot;100701&quot; changedsize&#x3D;&quot;true&quot; width&#x3D;&quot;560&quot; height&#x3D;&quot;788&quot;&gt;</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;观察该文本，<code>src=&quot;http://xxxxx.jpg&quot; size=</code>中引号内的部分才是图片的链接，所以正则表达式可以写为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pat = <span class="string">r&#x27;src=&quot;(.*?\.jpg)&quot; size=&#x27;</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后就可以开始批量筛选了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getimgurl</span>(<span class="params">t</span>):</span></span><br><span class="line">    pat = <span class="string">r&#x27;src=&quot;(.*?\.jpg)&quot; size=&#x27;</span></span><br><span class="line">    imglist = re.compile(pat).findall(t)</span><br><span class="line">    <span class="keyword">return</span> imglist</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;测试一下筛选效果如何。把所有识别出的链接都放在列表里，然后打印。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imglist = getimgurl(t)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> imglist:</span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果如下：<br><img src="https://img-blog.csdnimg.cn/20200322175833658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;看来OK。继续下一步。<br><br></p><h2 id="目标保存"><a href="#目标保存" class="headerlink" title="目标保存"></a>目标保存</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提取出来的这些链接如果不能将它们保存下载下来也无济于事，所以需要用到<code>urllib.request.urlretrieve</code>方法。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方法是将远程数据下载到本地，具体参数如下：<br><code>urlretrieve(url[, filename[, reporthook[, data]]])</code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>url</strong>是指远程数据的地址，<strong>filename</strong>是指保存到本地的路径，reporthook是一个回调函数，可以用来显示当前的下载进度，data是指post到服务器的数据，一般很少用到。具体可以参考<a href="https://blog.csdn.net/zzc15806/article/details/79636417">这篇文章</a>。这里我们就只使用前两个参数。编写函数，测试一下。<strong>（要注意每个图片下载路径的变化）</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveimg</span>(<span class="params">imglist</span>):</span></span><br><span class="line">    x = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> imglist:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            urllib.request.urlretrieve(img, <span class="string">&#x27;D:/study/pyimgtest/%d.jpg&#x27;</span> %x)</span><br><span class="line">            print(<span class="string">&quot;dl %d.jpg successfully&quot;</span> %x)</span><br><span class="line">            x = x + <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">&quot;failed to dl&quot;</span>)</span><br><span class="line">saveimg(imglist)</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;看下结果：<br><img src="https://img-blog.csdnimg.cn/20200322182921175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200322183009230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;搞定。<br><br></p><h2 id="多页爬取"><a href="#多页爬取" class="headerlink" title="多页爬取"></a>多页爬取</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然可以成功爬取一页，再试一下爬取多页。这里的<strong>url</strong>就会变化了，点击下一页看一下url的变化。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;原本的地址长这样。<br><img src="https://img-blog.csdnimg.cn/20200322183544842.png" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二页的地址长这样。多了个<code>?pn=2</code>。<br><img src="https://img-blog.csdnimg.cn/20200322183606709.png" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三页的地址也是，多了个<code>?pn=3</code>。<br><img src="https://img-blog.csdnimg.cn/2020032218362412.png" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击其他页面也是这样，所以可以推断除了第一页，其他页面都在第一页的<strong>url</strong>后加上了<code>?pn=x</code>，其中<code>x</code>表示页面号。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以可以加个识别字符<code>flag</code>代表页面号，起到识别页面和区分<strong>url</strong>的作用。然后就可以开始写循环了。<strong>注意中间加上<code>sleep</code>控制访问频率。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geturl</span>():</span></span><br><span class="line">    <span class="keyword">global</span> flag</span><br><span class="line">    <span class="keyword">if</span> flag==<span class="number">1</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://tieba.baidu.com/p/6520552534&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url=<span class="string">&#x27;https://tieba.baidu.com/p/6520552534?pn=%s&#x27;</span> %flag</span><br><span class="line">    time.sleep(<span class="number">1.3</span>)</span><br><span class="line">    print(<span class="string">&quot;ready for No. %s page&quot;</span> %flag)</span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line">   </span><br><span class="line"><span class="keyword">for</span> flag <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">5</span>):</span><br><span class="line">    url=geturl()</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;测试一下，结果如下：<strong>（代码中的<code>range(1,5)</code>是指flag从1增长到5，但不取5，所以flag取值为1到4。）</strong><br><img src="https://img-blog.csdnimg.cn/20200322184940478.png" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;循环成功，可以整合代码了 <strong>（最终代码见附录）</strong>，爬了4页图片及输出结果如下：<br><img src="https://img-blog.csdnimg.cn/20200322185700463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200322185735193.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很完美，换种方法可不可行呢？<br><br></p><h2 id="如果用urlopen——"><a href="#如果用urlopen——" class="headerlink" title="如果用urlopen——"></a>如果用urlopen——</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为我一开始学的就是用urlopen方法来进行爬取，所以在学习初期把<code>urllib.request.urlopen</code>和<code>requests.get</code>混淆了。上网查了一下资料，才将它们区分。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;requests库的<code>get</code>方法先构造一个向服务器请求资源的Request对象，这个对象是requests库内部生成的，而返回的是一个<strong>包含服务器资源的Response对象</strong>。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Response对象属性表：</p><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">status_code</td><td align="left">HTTP请求的返回状态，200表示连接成功，404表示连接失败</td></tr><tr><td align="left">text</td><td align="left">HTTP响应内容的字符串形式，即url对应的页面内容</td></tr><tr><td align="left">encoding</td><td align="left">从HTTP header中猜测的相应内容编码方式</td></tr><tr><td align="left">apparent_encoding</td><td align="left">从内容中分析出的响应内容编码方式</td></tr><tr><td align="left">content</td><td align="left">HTTP相应内容的二进制形式</td></tr></tbody></table><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;而`urllib`库中的请求方法若要携带请求头，则必须创建一个Request实例对象，这就需要用到`urllib.request.Request`方法。<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Request()</code>有如下参数：url，data，headers，origin_req_host，unverifiable，method。其中<strong>url</strong>指远程数据地址，data指携带至远程地址的数据，<strong>headers</strong>指请求头，method指请求方法。<em>（其余参数的意义尚未查到，后续补充）</em></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同样该方法也是先构造一个Request实例对象，然后返回一个<strong>包含服务器资源的Response对象的描述</strong>，再用<code>read</code>方法，返回的才是response对象里的内容，并且是bytes格式，所以最后还要用<code>decode</code>将字符串转换成unicode编码。<em>（此处与<code>requests.get</code>返回后需要<code>encoding</code>相似）</em></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以可以将上面编写的<code>getHtml</code>方法改写为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span>(<span class="params">url,headers</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = urllib.request.Request(url, data=<span class="literal">None</span>,headers=headers)</span><br><span class="line">        page=urllib.request.urlopen(res) </span><br><span class="line">        html = page.read().decode(<span class="string">&quot;utf8&quot;</span>) </span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">&quot;failed to geturl&quot;</span>)           <span class="comment"># 如果网络连接异常，则报错。</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> html</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;测试一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=getHtml(<span class="string">&#x27;https://tieba.baidu.com/p/6520552534&#x27;</span>,headers)</span><br><span class="line">print(t)</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果如下：<br><img src="https://img-blog.csdnimg.cn/20200322203209320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQxODU1OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;嗯嗯，没问题。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>整合后的代码如下：<br><em>（这是运用<code>requests</code>库版本的，要用<code>urllib</code>库就只用将<code>getHtml</code>按上面的方式改写即可）</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) \</span></span><br><span class="line"><span class="string">    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3314.0 Safari/537.36 SE 2.X MetaSr 1.0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;tieba.baidu.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,\</span></span><br><span class="line"><span class="string">    application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geturl</span>():</span></span><br><span class="line">    <span class="keyword">global</span> flag</span><br><span class="line">    <span class="keyword">if</span> flag==<span class="number">1</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://tieba.baidu.com/p/6520552534&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url=<span class="string">&#x27;https://tieba.baidu.com/p/6520552534?pn=%s&#x27;</span> %flag</span><br><span class="line">    time.sleep(<span class="number">1.3</span>)</span><br><span class="line">    print(<span class="string">&quot;ready for No. %s page&quot;</span> %flag)</span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span>(<span class="params">url,headers</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url,headers)</span><br><span class="line">        r.encoding=<span class="string">&#x27;utf8&#x27;</span> <span class="comment">#将对象编码转换成UTF-8编码</span></span><br><span class="line">        html=r</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">&quot;failed to geturl&quot;</span>)           <span class="comment"># 如果网络连接异常，则报错。</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getimgurl</span>(<span class="params">t</span>):</span></span><br><span class="line">    pat = <span class="string">r&#x27;src=&quot;(.*?\.jpg)&quot; size=&#x27;</span></span><br><span class="line">    imglist = re.compile(pat).findall(t)</span><br><span class="line">    <span class="keyword">return</span> imglist</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveimg</span>(<span class="params">imglist</span>):</span></span><br><span class="line">    <span class="keyword">global</span> flag</span><br><span class="line">    x = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> imglist:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            urllib.request.urlretrieve(img, <span class="string">&#x27;D:/study/pyimg/p%d-%d.jpg&#x27;</span> %(flag,x))</span><br><span class="line">            print(<span class="string">&quot;dl %d.jpg from page %d successfully&quot;</span> %(x,flag))</span><br><span class="line">            x = x + <span class="number">1</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">&quot;failed to dl&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> flag <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">5</span>):</span><br><span class="line">    url=geturl()</span><br><span class="line">    t = getHtml(url, headers=headers).text</span><br><span class="line">    imglist = getimgurl(t)</span><br><span class="line">    saveimg(imglist)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;重新温习一下被放下太久的Python爬虫技能</summary>
      
    
    
    
    <category term="python" scheme="https://zing1116.works/categories/python/"/>
    
    <category term="爬虫" scheme="https://zing1116.works/categories/python/%E7%88%AC%E8%99%AB/"/>
    
    
    <category term="爬虫" scheme="https://zing1116.works/tags/%E7%88%AC%E8%99%AB/"/>
    
    <category term="urllib库" scheme="https://zing1116.works/tags/urllib%E5%BA%93/"/>
    
    <category term="requests库" scheme="https://zing1116.works/tags/requests%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>あの街に住んでる彼らのこと</title>
    <link href="https://zing1116.works/2020/02/17/cishang/"/>
    <id>https://zing1116.works/2020/02/17/cishang/</id>
    <published>2020-02-17T04:21:37.000Z</published>
    <updated>2020-11-20T02:35:32.661Z</updated>
    
    <content type="html"><![CDATA[<p>图源：（对不起我真的忘了）<br>翻译：我<br>修图：我<br>嵌字：我<br>校对：我</p><p>HQ!! 阿吽</p><p>四天狂肝产物，封面已经要了本卑微鼠绘人士的命了。<br>修嵌练习不知不觉就被带偏成日翻练习了，有好多细节翻得没把握，到后面开始怀疑自己，甚至倒回去反复确认ゴリラ是不是只有大猩猩的意思……最后就开始自暴自弃。也是一次练习吧，下次继续。</p><p>请勿转载，喜欢请买本支持作者。</p><p><img src="https://i.loli.net/2020/11/20/fZNry5lkSXuVLBM.png" alt="1.png"><br><img src="https://i.loli.net/2020/11/20/KJRsi4YXdxpQCGO.png" alt="2.png"><br><img src="https://i.loli.net/2020/11/20/lAmY3QPtpyeTI2E.png" alt="3.png"><br><img src="https://i.loli.net/2020/11/20/QhYvzeE314kLMfK.png" alt="4.png"><br><img src="https://i.loli.net/2020/11/20/rXUhu4BGFOfmPAD.png" alt="5.png"><br><img src="https://i.loli.net/2020/11/20/1AzWSpcUrl3NMeG.png" alt="6.png"><br><img src="https://i.loli.net/2020/11/20/43KihL5HedOCt1a.png" alt="7.png"><br><img src="https://i.loli.net/2020/11/20/6Sao47eKZ2smpCi.png" alt="8.png"><br><img src="https://i.loli.net/2020/11/20/rm6g1IeHaVpPq5G.png" alt="9.png"><br><img src="https://i.loli.net/2020/11/20/q52JoD8stUAVgQF.png" alt="10.png"><br><img src="https://i.loli.net/2020/11/20/W7wFlp2638DOh1S.png" alt="11.png"><br><img src="https://i.loli.net/2020/11/20/YuNX4bMBE9lGUf1.png" alt="12.png"><br><img src="https://i.loli.net/2020/11/20/QlUa4k2RPbgtJFX.png" alt="13.png"><br><img src="https://i.loli.net/2020/11/20/kM25ZRSClBKTNet.png" alt="14.png"><br><img src="https://i.loli.net/2020/11/20/Bl7cWH6GUfwMsDZ.png" alt="15.png"><br><img src="https://i.loli.net/2020/11/20/vCfJmPSEbw23yRK.png" alt="16.png"><br><img src="https://i.loli.net/2020/11/20/JSnCQLVAzyTKINx.png" alt="17.png"><br><img src="https://i.loli.net/2020/11/20/YFi7vGQJOh4xEea.png" alt="18.png"><br><img src="https://i.loli.net/2020/11/20/zqGkWnOHyoxiJjv.png" alt="19.png"><br><img src="https://i.loli.net/2020/11/20/Tuo28j3AkN1HpOU.png" alt="20.png"><br><img src="https://i.loli.net/2020/11/20/sdPMkT3GZ8xamON.png" alt="21.png"><br><img src="https://i.loli.net/2020/11/20/yl3MioHROb1CfvZ.png" alt="22.png"><br><img src="https://i.loli.net/2020/11/20/zI2wFrNV9lg1ykf.png" alt="23.png"><br><img src="https://i.loli.net/2020/11/20/PVuxwck8AUbM3RL.png" alt="24.png"><br><img src="https://i.loli.net/2020/11/20/QprvTOARuKSwaG7.png" alt="25.png"><br><img src="https://i.loli.net/2020/11/20/3WlPsfVTR1LvNEo.png" alt="26.png"><br><img src="https://i.loli.net/2020/11/20/hL8Pe6iSf1tQBuI.png" alt="27.png"><br><img src="https://i.loli.net/2020/11/20/8TaMyEKCd1GuArj.png" alt="IMG_9569.png"><br><img src="https://i.loli.net/2020/11/20/Bgq916WkbKduzZH.jpg" alt="IMG_9570.JPG"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;图源：（对不起我真的忘了）&lt;br&gt;翻译：我&lt;br&gt;修图：我&lt;br&gt;嵌字：我&lt;br&gt;校对：我&lt;/p&gt;
&lt;p&gt;HQ!! 阿吽&lt;/p&gt;
&lt;p&gt;四天狂肝产物，封面已经要了本卑微鼠绘人士的命了。&lt;br&gt;修嵌练习不知不觉就被带偏成日翻练习了，有好多细节翻得没把握，到后面开始怀疑自己，甚</summary>
      
    
    
    
    <category term="漫画自汉化" scheme="https://zing1116.works/categories/%E6%BC%AB%E7%94%BB%E8%87%AA%E6%B1%89%E5%8C%96/"/>
    
    <category term="刺傷" scheme="https://zing1116.works/categories/%E6%BC%AB%E7%94%BB%E8%87%AA%E6%B1%89%E5%8C%96/%E5%88%BA%E5%82%B7/"/>
    
    
    <category term="漫画自汉化" scheme="https://zing1116.works/tags/%E6%BC%AB%E7%94%BB%E8%87%AA%E6%B1%89%E5%8C%96/"/>
    
    <category term="刺傷" scheme="https://zing1116.works/tags/%E5%88%BA%E5%82%B7/"/>
    
  </entry>
  
  <entry>
    <title>バイ·マイ·サイド play2.5</title>
    <link href="https://zing1116.works/2020/02/13/bms/"/>
    <id>https://zing1116.works/2020/02/13/bms/</id>
    <published>2020-02-13T12:06:56.000Z</published>
    <updated>2020-11-20T02:35:34.191Z</updated>
    
    <content type="html"><![CDATA[<p>图源：（对不起我真的忘了）<br>翻译：我<br>修图：我<br>嵌字：我<br>校对：我</p><p>第一次嵌字练习就拿夏目女神的bms最短话来开刀了。<br>嵌字好玩，有被爽到，下次继续。</p><p>请勿转载，喜欢请买书支持作者。<br><img src="https://ftp.bmp.ovh/imgs/2020/11/f3cb7ca22bc23783.png" alt="1"><br><img src="https://ftp.bmp.ovh/imgs/2020/11/04d96cc75231e3a0.png" alt="2"><br><img src="https://ftp.bmp.ovh/imgs/2020/11/c3f541e55fcf4c00.png" alt="3"><br><img src="https://ftp.bmp.ovh/imgs/2020/11/fbede25b29b72e7f.png" alt="4"><br><img src="https://ftp.bmp.ovh/imgs/2020/11/1a37a9d61544e0d8.png" alt="5"><br><img src="https://ftp.bmp.ovh/imgs/2020/11/d379bc912c2ee5b2.png" alt="6"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;图源：（对不起我真的忘了）&lt;br&gt;翻译：我&lt;br&gt;修图：我&lt;br&gt;嵌字：我&lt;br&gt;校对：我&lt;/p&gt;
&lt;p&gt;第一次嵌字练习就拿夏目女神的bms最短话来开刀了。&lt;br&gt;嵌字好玩，有被爽到，下次继续。&lt;/p&gt;
&lt;p&gt;请勿转载，喜欢请买书支持作者。&lt;br&gt;&lt;img src=&quot;htt</summary>
      
    
    
    
    <category term="漫画自汉化" scheme="https://zing1116.works/categories/%E6%BC%AB%E7%94%BB%E8%87%AA%E6%B1%89%E5%8C%96/"/>
    
    <category term="ナツメカズキ" scheme="https://zing1116.works/categories/%E6%BC%AB%E7%94%BB%E8%87%AA%E6%B1%89%E5%8C%96/%E3%83%8A%E3%83%84%E3%83%A1%E3%82%AB%E3%82%BA%E3%82%AD/"/>
    
    
    <category term="漫画自汉化" scheme="https://zing1116.works/tags/%E6%BC%AB%E7%94%BB%E8%87%AA%E6%B1%89%E5%8C%96/"/>
    
    <category term="ナツメカズキ" scheme="https://zing1116.works/tags/%E3%83%8A%E3%83%84%E3%83%A1%E3%82%AB%E3%82%BA%E3%82%AD/"/>
    
  </entry>
  
</feed>
